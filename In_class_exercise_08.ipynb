{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_08.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Explorer9/prabhu_INFO5731/blob/master/In_class_exercise_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4jS9dukRyou"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBn4HPZKRyov"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9eJ0zyRyow"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWqtTcl3Ryox",
        "outputId": "f7b88494-b249-459c-92ce-6e28f84cbcad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Write your code here\n",
        "import nltk  \n",
        "import numpy as np  \n",
        "import random  \n",
        "import string\n",
        "import pandas as pd\n",
        "import bs4 as bs  \n",
        "nltk.download('punkt')\n",
        "import urllib.request  \n",
        "import heapq\n",
        "import re  \n",
        "df=pd.read_csv(\"/content/Jokersentiments.csv\")\n",
        "article_text=[]\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vswgnrPvzKpQ"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "for i in df['clean_text']:\n",
        "  article_text.append(word_tokenize(i))"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr0mp1a9yAPr"
      },
      "source": [
        "documents=[]\n",
        "for i in range(len(df)-1):\n",
        "  words=word_tokenize((df['clean_text'])[i])\n",
        "  category=(df['Sentiment'])[i]\n",
        "  documents.append((words, category))\n",
        "random.shuffle(documents)\n",
        "all_words = nltk.FreqDist(article_text[1])\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1wl_fkriCij",
        "outputId": "5228691d-829e-49f8-990f-8790996bc958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train Naive Bayes classifier\n",
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[50:], featuresets[:50]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM3Z4siC5nFy",
        "outputId": "90827fdf-a8bc-4ffc-b611-ba1bd1b2d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "             contains(A) = True           Neutra : Positi =      7.2 : 1.0\n",
            "          contains(feel) = True           Neutra : Negati =      5.6 : 1.0\n",
            "        contains(people) = True           Neutra : Positi =      4.3 : 1.0\n",
            "           contains(But) = True           Neutra : Positi =      4.3 : 1.0\n",
            "         contains(world) = True           Neutra : Positi =      4.3 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9oYVNXRyo0"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSYThn87Ryo1",
        "outputId": "f9f47894-eb88-46a9-8a50-8db3aa723447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Write your code here\n",
        "#Textblob:\n",
        "nltk.download('vader_lexicon')\n",
        "import textblob\n",
        "from textblob import TextBlob\n",
        "testimonial = TextBlob((df['clean_text'])[1])\n",
        "print(testimonial.sentiment)\n",
        "\n",
        "#vader:\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader=SentimentIntensityAnalyzer()\n",
        "print(vader.polarity_scores((df['clean_text'])[1]))\n",
        "\n",
        "print(\"actual sentiment:\",(df['Sentiment'])[1])\n",
        "print(\"actual sentence:\",(df['clean_text'])[1])\n",
        "\n",
        "# Your analysis here:\n",
        "\n",
        "As vader is based on lexicons it defines the sentiment clearly, while textblob also defines about subjectivity which defines the extent of emotion of the sentence. The speaker of the sentence speaks more emotionally, \n",
        "which can be identified by the subjectvity from the textblob which is helpful in this case while vader gives the points based on the lexons it only speaks abput the positivity\n",
        "or negatvity of the sentence but not the emotion. So for identifying emotion of a person Textblob is better rathar than vader.\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "Sentiment(polarity=-0.03125, subjectivity=0.71875)\n",
            "{'neg': 0.12, 'neu': 0.649, 'pos': 0.232, 'compound': 0.9042}\n",
            "actual sentiment: Neutral\n",
            "actual sentence: This is a movie that only those who have felt alone and isolated can truly relate to it. You understand the motive and you feel sorry for the character. A lot of people will see this movie and think that it encourages violence. But truly, this movie should encourage each and every one of us to become a better person, treat everyone with respect and make each other feel like they belong in this world, instead of making them feel isolated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JUSS6XcBVhl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}